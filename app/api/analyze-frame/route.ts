// app/api/analyze-frame/route.ts
export const runtime = "nodejs";

import { type NextRequest, NextResponse } from "next/server"
import { z } from "zod"
import { getModel } from "@/lib/gemini";

const FrameAnalysisSchema = z.object({
  basketball: z.object({
    detected: z.boolean(),
    position: z
      .object({
        x: z.number(),
        y: z.number(),
      })
      .optional(),
    confidence: z.number().min(0).max(1),
  }),
  players: z.array(
    z.object({
      id: z.string(),
      position: z.object({
        x: z.number(),
        y: z.number(),
      }),
      pose: z.enum(["shooting", "dribbling", "defending", "running", "standing"]),
      jersey: z.string().optional(),
      confidence: z.number().min(0).max(1),
    }),
  ),
  basket: z.object({
    detected: z.boolean(),
    position: z
      .object({
        x: z.number(),
        y: z.number(),
      })
      .optional(),
    confidence: z.number().min(0).max(1),
  }),
  court: z.object({
    detected: z.boolean(),
    boundaries: z
      .array(
        z.object({
          x: z.number(),
          y: z.number(),
        }),
      )
      .optional(),
    confidence: z.number().min(0).max(1),
  }),
  action: z.enum(["shot_attempt", "dribbling", "passing", "defense", "transition", "none"]),
  timestamp: z.number(),
})

export async function POST(request: NextRequest) {
  try {
    const { frameData, timestamp } = await request.json()

    if (!frameData) {
      return NextResponse.json({ error: "No frame data provided" }, { status: 400 })
    }

    // In a real implementation, you would:
    // 1. Use computer vision models like YOLO or MediaPipe
    // 2. Detect objects in the frame (basketball, players, basket)
    // 3. Track player movements and poses
    // 4. Identify basketball-specific actions

    // For demonstration, we'll use AI to simulate frame analysis
    // Weâ€™ll ask Gemini to return STRICT JSON that matches the schema, then validate with zod.
    const model = getModel();
    const prompt = `Return ONLY valid JSON for the following schema (no markdown, no explanation):
    
    ${FrameAnalysisSchema.toString()}

    Context: Analyze this basketball game frame at timestamp ${timestamp} seconds. 
      
      Simulate realistic computer vision detection results for:
      - Basketball detection and position
      - Player positions and poses
      - Basket/hoop detection
      - Court boundaries
      - Current action being performed
      
      Generate realistic coordinates (0-1000 range) and confidence scores.
      Make the analysis consistent with a basketball game scenario.`;
    
      const result = await model.generateContent([{ text: prompt }]);
      const text = result.response.text().trim();
  
      // Try to parse and validate
      const parsed = FrameAnalysisSchema.safeParse(JSON.parse(text));
      if (!parsed.success) {
        return NextResponse.json(
          { error: "Model output failed schema validation", issues: parsed.error.format() },
          { status: 502 }
        );
      }
  
      return NextResponse.json({ success: true, timestamp, analysis: parsed.data });
    } catch (error) {
      console.error("Frame analysis error:", error);
      return NextResponse.json({ error: "Frame analysis failed" }, { status: 500 });
    }
  }